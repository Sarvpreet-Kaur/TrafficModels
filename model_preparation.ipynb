{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24039,"status":"ok","timestamp":1763037175694,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"cX_30xPEFF8F","outputId":"758eae7f-e223-4e52-8af5-dcc074708c5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8615,"status":"ok","timestamp":1763037184307,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"tlzruScjFMEk","outputId":"8beb6ed4-9f81-4a73-e47f-07c5a61fb805"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.228-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n","Requirement already satisfied: numpy\u003e=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib\u003e=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python\u003e=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow\u003e=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml\u003e=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch\u003e=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n","Requirement already satisfied: torchvision\u003e=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Collecting ultralytics-thop\u003e=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: absl-py\u003e=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c6.0.0dev,\u003e=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six\u003e=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n","Requirement already satisfied: typing-extensions\u003e=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n","Requirement already satisfied: keras\u003e=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: h5py\u003e=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n","Requirement already satisfied: ml-dtypes\u003c1.0.0,\u003e=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras\u003e=3.5.0-\u003etensorflow) (0.17.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.3.3)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (4.60.1)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (1.4.9)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (3.2.5)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib\u003e=3.3.0-\u003eultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.4.4)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (3.11)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests\u003e=2.23.0-\u003eultralytics) (2025.10.5)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (3.10)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0-\u003etensorflow) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.20.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch\u003e=1.8.0-\u003eultralytics) (3.4.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch\u003e=1.8.0-\u003eultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard~=2.19.0-\u003etensorflow) (3.0.3)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (4.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich-\u003ekeras\u003e=3.5.0-\u003etensorflow) (0.1.2)\n","Downloading ultralytics-8.3.228-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.228 ultralytics-thop-2.0.18\n"]}],"source":["!pip install ultralytics scikit-learn opencv-python-headless tensorflow joblib tqdm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25882,"status":"ok","timestamp":1763037210189,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"NX1TccLrFMBw","outputId":"2d130d2a-fbe1-4777-9412-3f49abc561f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["import os\n","import cv2\n","import joblib\n","import numpy as np\n","from tqdm import tqdm\n","from ultralytics import YOLO\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":544,"status":"ok","timestamp":1763037210739,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"wUUQpcfQFL_E","outputId":"3485c0b6-44e3-4600-9dbe-ec0f63a04e85"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 50.1MB/s 0.1s\n"]}],"source":["# Paths in your Google Drive\n","train_dir = \"/content/drive/MyDrive/dataset1/train\"\n","val_dir   = \"/content/drive/MyDrive/dataset1/val\"\n","\n","# Model save paths\n","model_path = \"/content/drive/MyDrive/vehicle_classifier.pkl\"\n","encoder_path = \"/content/drive/MyDrive/label_encoder.pkl\"\n","\n","# YOLO model (for detection)\n","yolo_model = YOLO('yolov8n.pt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4829,"status":"ok","timestamp":1763037215608,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"5PzzcF3DFL8B","outputId":"7dbe5e46-9f5f-480d-ae18-1540064d58f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"]}],"source":["# Pre-trained ResNet50 (no top layer)\n","resnet = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n","\n","def extract_features(img_path):\n","    try:\n","        img = image.load_img(img_path, target_size=(224, 224))\n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)\n","        x = preprocess_input(x)\n","        features = resnet.predict(x, verbose=0)\n","        return features.flatten()\n","    except Exception as e:\n","        print(f\"Error processing {img_path}: {e}\")\n","        return np.zeros((2048,))\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261021,"status":"ok","timestamp":1763039341380,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"fonmx_5qFL5M","outputId":"91fae178-7089-4fe9-c4b0-2f05009f8e93"},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading normal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2704/2704 [16:43\u003c00:00,  2.69it/s]\n","Loading emergency: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2239/2239 [13:53\u003c00:00,  2.69it/s]\n","Loading normal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 300/300 [01:52\u003c00:00,  2.68it/s]\n","Loading emergency: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 444/444 [02:44\u003c00:00,  2.69it/s]\n"]}],"source":["def load_data(data_dir):\n","    X, y = [], []\n","    classes = os.listdir(data_dir)\n","    for cls in classes:\n","        cls_path = os.path.join(data_dir, cls)\n","        if not os.path.isdir(cls_path):\n","            continue\n","        for img_name in tqdm(os.listdir(cls_path), desc=f\"Loading {cls}\"):\n","            img_path = os.path.join(cls_path, img_name)\n","            feats = extract_features(img_path)\n","            X.append(feats)\n","            y.append(cls)\n","    return np.array(X), np.array(y)\n","\n","# Load training data\n","X_train, y_train = load_data(train_dir)\n","# Load validation data\n","X_val, y_val = load_data(val_dir)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15310,"status":"ok","timestamp":1763039356702,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"n5Yxczz_FLeG","outputId":"a92be25f-f397-4bd9-caa9-fad9f7728f15"},"outputs":[{"name":"stdout","output_type":"stream","text":["‚úÖ Validation Accuracy: 100.00%\n","‚úÖ Model and encoder saved successfully!\n"]}],"source":["# Encode labels\n","le = LabelEncoder()\n","y_train_enc = le.fit_transform(y_train)\n","y_val_enc = le.transform(y_val)\n","\n","# Train Random Forest\n","clf = RandomForestClassifier(n_estimators=100, random_state=42)\n","clf.fit(X_train, y_train_enc)\n","\n","# Validate\n","y_pred = clf.predict(X_val)\n","acc = accuracy_score(y_val_enc, y_pred)\n","print(f\"‚úÖ Validation Accuracy: {acc*100:.2f}%\")\n","\n","# Save model + encoder\n","joblib.dump(clf, model_path)\n","joblib.dump(le, encoder_path)\n","print(\"‚úÖ Model and encoder saved successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hbjm0HyPFRxG"},"outputs":[],"source":["# # Load trained model\n","# clf = joblib.load(model_path)\n","# le = joblib.load(encoder_path)\n","\n","# # Input and output video paths\n","# input_video = \"/content/drive/MyDrive/test_videos/traffic2.mp4\"   # change this path to your video\n","# output_video = \"/content/drive/MyDrive/output/processed_output.mp4\"\n","\n","# # Open video\n","# cap = cv2.VideoCapture(input_video)\n","# fps = cap.get(cv2.CAP_PROP_FPS)\n","# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","# out = cv2.VideoWriter(output_video, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n","\n","# frame_count = 0\n","\n","# while True:\n","#     ret, frame = cap.read()\n","#     if not ret:\n","#         break\n","#     frame_count += 1\n","\n","#     # Process every 6th frame\n","#     if frame_count % 6 != 0:\n","#         continue\n","\n","#     # YOLO vehicle detection\n","#     results = yolo_model(frame)\n","#     detections = results[0].boxes\n","\n","#     emergency_count = 0\n","#     normal_count = 0\n","\n","#     for box in detections:\n","#         cls_id = int(box.cls)\n","#         cls_name = yolo_model.names[cls_id].lower()\n","\n","#         # Only detect vehicles\n","#         if any(x in cls_name for x in ['car', 'bus', 'truck', 'motorcycle', 'ambulance']):\n","#             x1, y1, x2, y2 = map(int, box.xyxy[0])\n","#             cropped = frame[y1:y2, x1:x2]\n","\n","#             if cropped.size == 0:\n","#                 continue\n","\n","#             # Feature extraction and classification\n","#             img = cv2.resize(cropped, (224, 224))\n","#             x = np.expand_dims(img, axis=0)\n","#             x = preprocess_input(x)\n","#             features = resnet.predict(x, verbose=0).flatten().reshape(1, -1)\n","#             pred = clf.predict(features)\n","#             label = le.inverse_transform(pred)[0]\n","\n","#             color = (0, 0, 255) if label == \"emergency\" else (0, 255, 0)\n","#             if label == \"emergency\":\n","#                 emergency_count += 1\n","#             else:\n","#                 normal_count += 1\n","\n","#             cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n","#             cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n","\n","#     print(f\"Frame {frame_count}: Emergency = {emergency_count}, Normal = {normal_count}\")\n","#     out.write(frame)\n","\n","# cap.release()\n","# out.release()\n","# print(\"‚úÖ Processed video saved at:\", output_video)\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1763039356712,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"gCsxD5ifX_Ym"},"outputs":[],"source":["# video_path = \"/content/drive/MyDrive/test_video/traffic2.mp4\"   # \u003c-- your video path\n","\n","# cap = cv2.VideoCapture(video_path)\n","# if not cap.isOpened():\n","#     raise Exception(\"‚ùå Could not open video. Check your path!\")\n","\n","# frame_count = 0\n","\n","# print(\"üîç Starting vehicle detection and classification...\\n\")\n","\n","# while True:\n","#     ret, frame = cap.read()\n","#     if not ret:\n","#         break\n","#     frame_count += 1\n","\n","#     # Process every 6th frame only\n","#     if frame_count % 6 != 0:\n","#         continue\n","\n","#     results = yolo_model(frame, verbose=False)\n","#     boxes = results[0].boxes\n","\n","#     emergency_count = 0\n","#     normal_count = 0\n","\n","#     if boxes is not None and len(boxes) \u003e 0:\n","#         for box in boxes:\n","#             cls_id = int(box.cls)\n","#             cls_name = yolo_model.names[cls_id].lower()\n","\n","#             # Detect only relevant vehicle types\n","#             if any(v in cls_name for v in ['car', 'bus', 'truck', 'motorcycle', 'ambulance']):\n","#                 x1, y1, x2, y2 = map(int, box.xyxy[0])\n","#                 cropped = frame[y1:y2, x1:x2]\n","#                 if cropped.size == 0:\n","#                     continue\n","\n","#                 # Feature extraction and classification\n","#                 img = cv2.resize(cropped, (224, 224))\n","#                 x = np.expand_dims(img, axis=0)\n","#                 x = preprocess_input(x)\n","#                 feats = resnet.predict(x, verbose=0).flatten().reshape(1, -1)\n","#                 pred  = clf.predict(feats)\n","#                 label = le.inverse_transform(pred)[0]\n","\n","#                 if label == \"emergency\":\n","#                     emergency_count += 1\n","#                 else:\n","#                     normal_count += 1\n","\n","#     # ‚úÖ Always print even if zero detected\n","#     print(f\"Frame {frame_count}: Emergency = {emergency_count}, Normal = {normal_count}\")\n","\n","# cap.release()\n","# print(\"\\n‚úÖ Finished processing video.\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true,"executionInfo":{"elapsed":1,"status":"ok","timestamp":1763039356715,"user":{"displayName":"DynamicTrafficControl","userId":"02576698071224962586"},"user_tz":-330},"id":"ZYtvpGSVZJ60"},"outputs":[],"source":["# from google.colab.patches import cv2_imshow\n","# import cv2\n","# import numpy as np\n","\n","# video_path = \"/content/drive/MyDrive/test_video/traffic1.mp4\"  # \u003c-- change this to your video path\n","\n","# cap = cv2.VideoCapture(video_path)\n","# if not cap.isOpened():\n","#     raise Exception(\"‚ùå Could not open video. Check your path!\")\n","\n","# frame_count = 0\n","# print(\"üöó Starting vehicle detection + classification...\\n\")\n","\n","# while True:\n","#     ret, frame = cap.read()\n","#     if not ret:\n","#         break\n","#     frame_count += 1\n","\n","#     # Process every 6th frame only\n","#     if frame_count % 6 != 0:\n","#         continue\n","\n","#     results = yolo_model(frame, verbose=False)\n","#     boxes = results[0].boxes\n","\n","#     emergency_count = 0\n","#     normal_count = 0\n","\n","#     if boxes is not None and len(boxes) \u003e 0:\n","#         for box in boxes:\n","#             cls_id = int(box.cls)\n","#             cls_name = yolo_model.names[cls_id].lower()\n","\n","#             # Only classify vehicles\n","#             if any(v in cls_name for v in ['car', 'bus', 'truck', 'motorcycle', 'ambulance']):\n","#                 x1, y1, x2, y2 = map(int, box.xyxy[0])\n","#                 cropped = frame[y1:y2, x1:x2]\n","#                 if cropped.size == 0:\n","#                     continue\n","\n","#                 # Resize + extract features\n","#                 img = cv2.resize(cropped, (224, 224))\n","#                 x = np.expand_dims(img, axis=0)\n","#                 x = preprocess_input(x)\n","#                 feats = resnet.predict(x, verbose=0).flatten().reshape(1, -1)\n","#                 pred = clf.predict(feats)\n","#                 label = le.inverse_transform(pred)[0]\n","\n","#                 # Counting + box color\n","#                 if label == \"emergency\":\n","#                     emergency_count += 1\n","#                     color = (0, 0, 255)  # red\n","#                 else:\n","#                     normal_count += 1\n","#                     color = (0, 255, 0)  # green\n","\n","#                 # Draw bounding box + label\n","#                 cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n","#                 cv2.putText(frame, label, (x1, y1 - 10),\n","#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n","\n","#     # Print frame counts\n","#     print(f\"Frame {frame_count}: Emergency = {emergency_count}, Normal = {normal_count}\")\n","\n","#     # Show the processed frame\n","#     display_frame = cv2.resize(frame, (640, 360))\n","#     cv2_imshow(display_frame)\n","\n","# cap.release()\n","# print(\"\\n‚úÖ Finished processing video.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1dG0p3-6umlUQ3o43LGuwL73NQK4Z-UhX"},"id":"Ghx4e9HEgNNP","outputId":"e6f4581c-e56b-4563-8334-9b9edd35a1c3"},"outputs":[],"source":["# ==================== STEP 1: Upload video from local machine ====================\n","from google.colab import files\n","import cv2\n","import numpy as np\n","\n","# Upload a video from your computer\n","uploaded = files.upload()\n","\n","# Get uploaded filename\n","for filename in uploaded.keys():\n","    video_path = f\"/content/{filename}\"  # path for OpenCV\n","\n","print(f\"‚úÖ Uploaded video: {video_path}\")\n","\n","\n","# ==================== STEP 2: Vehicle detection + classification ====================\n","from google.colab.patches import cv2_imshow\n","\n","# Make sure your trained models are already loaded:\n","#  - yolo_model  (YOLOv8)\n","#  - resnet      (ResNet50 feature extractor)\n","#  - clf         (trained RandomForestClassifier)\n","#  - le          (LabelEncoder)\n","#  - preprocess_input (from keras.applications.resnet50)\n","#  If you just trained them earlier in this Colab, they are already available.\n","\n","cap = cv2.VideoCapture(video_path)\n","if not cap.isOpened():\n","    raise Exception(\"‚ùå Could not open uploaded video. Please re-upload it.\")\n","\n","frame_count = 0\n","print(\"üöó Starting vehicle detection + classification...\\n\")\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    frame_count += 1\n","\n","    # Process every 6th frame\n","    if frame_count % 6 != 0:\n","        continue\n","\n","    results = yolo_model(frame, verbose=False)\n","    boxes = results[0].boxes\n","\n","    emergency_count = 0\n","    normal_count = 0\n","\n","    if boxes is not None and len(boxes) \u003e 0:\n","        for box in boxes:\n","            cls_id = int(box.cls)\n","            cls_name = yolo_model.names[cls_id].lower()\n","\n","            # Detect only vehicles\n","            if any(v in cls_name for v in ['car', 'bus', 'truck', 'motorcycle', 'ambulance']):\n","                x1, y1, x2, y2 = map(int, box.xyxy[0])\n","                cropped = frame[y1:y2, x1:x2]\n","                if cropped.size == 0:\n","                    continue\n","\n","                # Preprocess + extract features\n","                img = cv2.resize(cropped, (224, 224))\n","                x = np.expand_dims(img, axis=0)\n","                x = preprocess_input(x)\n","                feats = resnet.predict(x, verbose=0).flatten().reshape(1, -1)\n","                pred = clf.predict(feats)\n","                label = le.inverse_transform(pred)[0]\n","\n","                # Counting + box color\n","                if label == \"emergency\":\n","                    emergency_count += 1\n","                    color = (0, 0, 255)  # red\n","                else:\n","                    normal_count += 1\n","                    color = (0, 255, 0)  # green\n","\n","                # Draw bounding box + label\n","                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n","                cv2.putText(frame, label, (x1, y1 - 10),\n","                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n","\n","    # Print results for this frame\n","    print(f\"Frame {frame_count}: Emergency = {emergency_count}, Normal = {normal_count}\")\n","\n","    # Show annotated frame\n","    display_frame = cv2.resize(frame, (640, 360))\n","    cv2_imshow(display_frame)\n","\n","cap.release()\n","print(\"\\n‚úÖ Finished processing uploaded video.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vYRX616HhCrd"},"outputs":[{"data":{"text/html":["\n","     \u003cinput type=\"file\" id=\"files-b06c2605-8f9b-4c17-8f8a-72334f1a5e1f\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" /\u003e\n","     \u003coutput id=\"result-b06c2605-8f9b-4c17-8f8a-72334f1a5e1f\"\u003e\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      \u003c/output\u003e\n","      \u003cscript\u003e// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) =\u003e {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable\u003c!Object\u003e} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) =\u003e {\n","    inputElement.addEventListener('change', (e) =\u003e {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) =\u003e {\n","    cancel.onclick = () =\u003e {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) =\u003e {\n","      const reader = new FileReader();\n","      reader.onload = (e) =\u003e {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position \u003c fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","\u003c/script\u003e "],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# ==================== STEP 1: Upload video from local machine ====================\n","from google.colab import files\n","import cv2\n","import numpy as np\n","\n","# Upload a video from your computer\n","uploaded = files.upload()\n","\n","# Get uploaded filename\n","for filename in uploaded.keys():\n","    video_path = f\"/content/{filename}\"  # path for OpenCV\n","\n","print(f\"‚úÖ Uploaded video: {video_path}\")\n","\n","\n","# ==================== STEP 2: Vehicle detection + classification (count only) ====================\n","# Make sure your trained models are already loaded:\n","#  - yolo_model  (YOLOv8)\n","#  - resnet      (ResNet50 feature extractor)\n","#  - clf         (trained RandomForestClassifier)\n","#  - le          (LabelEncoder)\n","#  - preprocess_input (from keras.applications.resnet50)\n","# If you just trained them earlier in this Colab, they‚Äôre already available.\n","\n","cap = cv2.VideoCapture(video_path)\n","if not cap.isOpened():\n","    raise Exception(\"‚ùå Could not open uploaded video. Please re-upload it.\")\n","\n","frame_count = 0\n","print(\"üöó Starting vehicle detection + classification...\\n\")\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    frame_count += 1\n","\n","    # Process every 6th frame only\n","    if frame_count % 6 != 0:\n","        continue\n","\n","    results = yolo_model(frame, verbose=False)\n","    boxes = results[0].boxes\n","\n","    emergency_count = 0\n","    normal_count = 0\n","\n","    if boxes is not None and len(boxes) \u003e 0:\n","        for box in boxes:\n","            cls_id = int(box.cls)\n","            cls_name = yolo_model.names[cls_id].lower()\n","\n","            # Only classify vehicles\n","            if any(v in cls_name for v in ['car', 'bus', 'truck', 'motorcycle', 'ambulance']):\n","                x1, y1, x2, y2 = map(int, box.xyxy[0])\n","                cropped = frame[y1:y2, x1:x2]\n","                if cropped.size == 0:\n","                    continue\n","\n","                # Preprocess + extract features\n","                img = cv2.resize(cropped, (224, 224))\n","                x = np.expand_dims(img, axis=0)\n","                x = preprocess_input(x)\n","                feats = resnet.predict(x, verbose=0).flatten().reshape(1, -1)\n","                pred = clf.predict(feats)\n","                label = le.inverse_transform(pred)[0]\n","\n","                # Counting only (no drawing)\n","                if label == \"emergency\":\n","                    emergency_count += 1\n","                else:\n","                    normal_count += 1\n","\n","    # Print results for this frame\n","    print(f\"Frame {frame_count}: Emergency = {emergency_count}, Normal = {normal_count}\")\n","\n","cap.release()\n","print(\"\\n‚úÖ Finished processing uploaded video.\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMynACRutKU0kBBOxUAtyNe","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}